{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bddfc976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yaml import load, dump\n",
    "import json\n",
    "\n",
    "JOB_NAME = \"cargo_doc\"\n",
    "INPUT_FILE = \"github/\" + JOB_NAME + \".yml\"\n",
    "OUTPUT_FILE = \"Outputs/github/\" + JOB_NAME + \".json\"\n",
    "OUTPUT_JOB = \"Outputs/gitlab/\" + JOB_NAME + \".yml\"\n",
    "\n",
    "try:\n",
    "    from yaml import CLoader as Loader, CDumper as Dumper\n",
    "except ImportError:\n",
    "    from yaml import Loader, Dumper\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "126d6699",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_file = open(INPUT_FILE, 'r')\n",
    "yaml_content = load(yaml_file, Loader=Loader)\n",
    "# with open(OUTPUT_FILE, \"w\") as outfile:\n",
    "#     json.dump(yaml_content, outfile)\n",
    "# print(\"Key: Value\")\n",
    "# for key, value in yaml_content.items():\n",
    "#     print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfe04f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def browseDict(keyElt, dictionary):\n",
    "    NOT_FOUND = \"\"\n",
    "    for key, value in dictionary.items():        \n",
    "        if (key == keyElt):\n",
    "            return (keyElt, value)\n",
    "        if (isinstance(value,dict)):\n",
    "            result = browseDict(keyElt, value)\n",
    "            if(result != NOT_FOUND):\n",
    "                return result\n",
    "    return NOT_FOUND           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d5511e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variables(dictionary):\n",
    "    variables = {}\n",
    "    _, value = browseDict(\"workflow_call\", dictionary)\n",
    "    inputs = value.get(\"inputs\", \"\")\n",
    "    secrets = value.get(\"secrets\", \"\")\n",
    "    if(inputs):\n",
    "        for key, value in inputs.items():\n",
    "            variables[key] = value.get(\"default\", \"\")\n",
    "    if(secrets):\n",
    "        for key, value in secrets.items():\n",
    "            variables[key] = value.get(\"default\", \"\")\n",
    "    return variables\n",
    "\n",
    "#get_variables(yaml_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18221814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_docker_image(job):\n",
    "    container = job.get(\"container\", \"\")\n",
    "    if(container):\n",
    "        if(isinstance(container, str)):\n",
    "            return container\n",
    "        elif(isinstance(container, dict)):\n",
    "            return container.get(\"image\", \"\")\n",
    "    return \"\"\n",
    "    \n",
    "def get_runs_on(job):\n",
    "    return job.get(\"runs-on\", \"\")\n",
    "\n",
    "def get_steps(job):\n",
    "    return job.get(\"steps\", [])\n",
    "\n",
    "def get_artifacts(steps):\n",
    "    artifacts = {}\n",
    "    for elt in steps:\n",
    "        if \"actions/upload-artifact\" in elt.get(\"uses\", \"\"):\n",
    "            artifacts[\"name\"] = elt[\"with\"].get(\"name\", \"\")\n",
    "            artifacts[\"paths\"] = elt[\"with\"].get(\"path\", \"\").splitlines()\n",
    "            artifacts[\"expire_in\"] = elt[\"with\"].get(\"retention-days\", \"\")\n",
    "            when = elt.get(\"if\", \"\")\n",
    "            if when == \"failure()\":\n",
    "                artifacts[\"when\"] = \"on_failure\"\n",
    "            elif when == \"always()\":\n",
    "                artifacts[\"when\"] = \"always\"\n",
    "            else:\n",
    "                artifacts[\"when\"] = \"on_success\"\n",
    "                \n",
    "    return artifacts\n",
    "    \n",
    "def get_cache(steps):\n",
    "    cache = {}\n",
    "    for elt in steps:\n",
    "        if \"actions/cache\" in elt.get(\"uses\", \"\"):\n",
    "            cache[\"key\"] = elt[\"with\"].get(\"key\", \"\")\n",
    "            cache[\"paths\"] = elt[\"with\"].get(\"path\", \"\").splitlines()\n",
    "    return cache\n",
    "\n",
    "def get_script(steps):\n",
    "    script = []\n",
    "    for step in steps:\n",
    "        if \"run\" in step:\n",
    "            lines = step.get(\"run\").splitlines()\n",
    "            for line in lines:\n",
    "                script.append(line)\n",
    "    return script\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb3a42a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cargo_doc:\n",
      "  artifacts:\n",
      "    expire_in: 15\n",
      "    name: Documentation\n",
      "    paths:\n",
      "    - ${{ env.OUTPUT_FOLDER }}\n",
      "    when: on_success\n",
      "  image: rust:1.57-buster\n",
      "  script:\n",
      "  - echo \"CIWORKSPACE_PATH=$GITHUB_WORKSPACE\" >> $GITHUB_ENV\n",
      "  - cd ${{ inputs.PROJECT_ROOT }}\n",
      "  - echo \"PROJECT_ROOT_RELATIVE_PATH=$(pwd)\" >> $GITHUB_ENV\n",
      "  - 'echo \"GITHUB_WORKSPACE : $GITHUB_WORKSPACE\" '\n",
      "  - cd ${{ inputs.PROJECT_ROOT }}\n",
      "  - if [ ! -f \"Cargo.toml\" ]; then\n",
      "  - '  echo \"ERROR --> Any Cargo.toml file isn''t present in the given root project\n",
      "    folder ${{ inputs.PROJECT_ROOT }}\"'\n",
      "  - '  echo \"INSIDE_IF_PATH=$(pwd)\" >> $GITHUB_ENV'\n",
      "  - fi\n",
      "  - echo \"ADDITIONAL_OPTIONS=${{inputs.ADDITIONAL_OPTIONS}}\" >> $GITHUB_ENV\n",
      "  - echo \"OUTPUT_FOLDER=${{inputs.OUTPUT_FOLDER}}\" >> $GITHUB_ENV\n",
      "  - if [ ${{ inputs.ONLY_LIB }} ]; then\n",
      "  - '  echo \"ADDITIONAL_OPTIONS=${{env.ADDITIONAL_OPTIONS}} --lib\" >> $GITHUB_ENV'\n",
      "  - fi\n",
      "  - if [ ${{ inputs.RELEASE_MODE }} ]; then\n",
      "  - '  echo \"ADDITIONAL_OPTIONS=${{env.ADDITIONAL_OPTIONS}} --release\" >> $GITHUB_ENV'\n",
      "  - fi\n",
      "  - if [ ! ${{env.PROJECT_ROOT_RELATIVE_PATH}} -ef ${{env.CIWORKSPACE_PATH}} ]; then\n",
      "  - '  echo \"Both paths are different. Test result negation : $? \"'\n",
      "  - '  echo \"OUTPUT_FOLDER=$GITHUB_WORKSPACE/${{ inputs.OUTPUT_FOLDER }}\" >> $GITHUB_ENV'\n",
      "  - 'fi   '\n",
      "  - 'echo \"Inputs ONLY_LIB: ${{ inputs.ONLY_LIB }}, RELEASE_MODE: ${{ inputs.RELEASE_MODE\n",
      "    }}\"'\n",
      "  - 'echo \"Inputs OUTPUT_FOLDER: ${{ inputs.OUTPUT_FOLDER }}, ADDITIONAL_OPTIONS:\n",
      "    ${{ inputs.ADDITIONAL_OPTIONS }}\"'\n",
      "  - 'echo \"Env updates OUTPUT_FOLDER: ${{ env.OUTPUT_FOLDER }}, ADDITIONAL_OPTIONS:\n",
      "    ${{ env.ADDITIONAL_OPTIONS }}\"'\n",
      "  - 'echo \"PROJECT_ROOT_RELATIVE_PATH : ${{env.PROJECT_ROOT_RELATIVE_PATH}} and GITHUB_WORKSPACE\n",
      "    : $GITHUB_WORKSPACE / its context: ${{github.workspace}}\"'\n",
      "  - cd ${{ inputs.PROJECT_ROOT }}\n",
      "  - cargo doc --target-dir ${{env.OUTPUT_FOLDER}} ${{ env.ADDITIONAL_OPTIONS }}\n",
      "  variables:\n",
      "    ADDITIONAL_OPTIONS: ''\n",
      "    ONLY_LIB: false\n",
      "    OUTPUT_FOLDER: website_build\n",
      "    PROJECT_ROOT: .\n",
      "    RELEASE_MODE: true\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from os.path import basename, splitext\n",
    "# from collections import OrderedDict\n",
    "_,jobs = browseDict(\"jobs\", yaml_content)\n",
    "gitlab_cicd_dict = {}\n",
    "variables = get_variables(yaml_content)\n",
    "for job_name, job in jobs.items():\n",
    "    gitlab_cicd_dict[job_name] = {}\n",
    "    image = get_docker_image(job)\n",
    "    if image:\n",
    "        gitlab_cicd_dict[job_name][\"image\"] = image\n",
    "    gitlab_cicd_dict[job_name][\"variables\"] = variables\n",
    "    steps = get_steps(job)\n",
    "    cache = get_cache(steps)\n",
    "    if cache:\n",
    "        gitlab_cicd_dict[job_name][\"cache\"] = cache\n",
    "    script = get_script(steps)\n",
    "    gitlab_cicd_dict[job_name][\"script\"] = script\n",
    "    artifacts = get_artifacts(steps)\n",
    "    if artifacts:\n",
    "        gitlab_cicd_dict[job_name][\"artifacts\"] = artifacts\n",
    "\n",
    "with open(OUTPUT_JOB, 'w') as job_file:\n",
    "    dump(gitlab_cicd_dict, job_file)\n",
    "yml_result = dump(gitlab_cicd_dict, Dumper=Dumper)\n",
    "print(yml_result)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b9e96ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('reusable-cypress_run',\n",
       " {'runs-on': 'ubuntu-latest',\n",
       "  'steps': [{'uses': 'actions/checkout@v2'},\n",
       "   {'name': 'Cache node modules',\n",
       "    'uses': 'actions/cache@v2',\n",
       "    'env': {'cache-name': 'cache-node-modules'},\n",
       "    'with': {'path': '~/.npm\\n~/.cache/Cypress\\n',\n",
       "     'key': \"${{runner.os}}-build-${{env.cache-name}}-${{hashFiles('**/package-lock.json')}}\",\n",
       "     'restore-keys': '${{runner.os}}-build-${{env.cache-name}}-\\n'}},\n",
       "   {'name': 'Install dependencies', 'run': 'npm ci'},\n",
       "   {'name': 'Install wait-on package', 'run': 'npm i -g wait-on'},\n",
       "   {'name': 'Make Cypress wait until the server is up and available',\n",
       "    'run': 'if [ ! -z ${{inputs.CYPRESS_BASE_URL}} ]; then\\n    npm start --no-clipboard & wait-on $CYPRESS_BASE_URL\\nelse \\n    echo \"Variable CYPRESS_BASE_URL is MANDATORY. You must fill it !\"\\n    exit 1\\nfi\\n'},\n",
       "   {'name': 'Run Cypress tests',\n",
       "    'run': 'if [ ! -z ${{secrets.CYPRESS_RECORD_KEY}} ]; then\\n    npx cypress run -P ${{inputs.CYPRESS_PROJECT_PATH}} -C ${{inputs.CYPRESS_CONFIG_FILE}} -r ${{inputs.CYPRESS_REPORTER}} ${{inputs.ADDITIONAL_OPTIONS}} --record\\nelse\\n    npx cypress run -P ${{inputs.CYPRESS_PROJECT_PATH}} -C ${{inputs.CYPRESS_CONFIG_FILE}} -r ${{inputs.CYPRESS_REPORTER}} ${{env.ADDITIONAL_OPTIONS}}\\nfi\\n',\n",
       "    'env': {'GITHUB_TOKEN': '${{secrets.GITHUB_TOKEN}}',\n",
       "     'if': '${{secrets.CYPRESS_RECORD_KEY}}',\n",
       "     'CYPRESS_RECORD_KEY': '${{secrets.CYPRESS_RECORD_KEY}}'}},\n",
       "   {'name': 'Archive Cypress videos',\n",
       "    'uses': 'actions/upload-artifact@v2',\n",
       "    'if': 'always()',\n",
       "    'with': {'name': 'cypress-videos',\n",
       "     'path': 'cypress/videos',\n",
       "     'if-no-files-found': 'error',\n",
       "     'retention-days': 15}},\n",
       "   {'name': 'Archive Cypress screenshots when job failed',\n",
       "    'uses': 'actions/upload-artifact@v2',\n",
       "    'if': 'failure()',\n",
       "    'with': {'name': 'cypress-screenshots',\n",
       "     'path': 'cypress/screenshots',\n",
       "     'if-no-files-found': 'error',\n",
       "     'retention-days': 15}}]})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_list = []\n",
    "_,jobs = browseDict(\"jobs\", yaml_content)\n",
    "for key, value in jobs.items():\n",
    "    jobs_list.append((key, value))\n",
    "_, job = jobs_list[0]\n",
    "jobs_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abf7fe58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['npm ci',\n",
       " 'npm i -g wait-on',\n",
       " 'if [ ! -z ${{inputs.CYPRESS_BASE_URL}} ]; then',\n",
       " '    npm start --no-clipboard & wait-on $CYPRESS_BASE_URL',\n",
       " 'else ',\n",
       " '    echo \"Variable CYPRESS_BASE_URL is MANDATORY. You must fill it !\"',\n",
       " '    exit 1',\n",
       " 'fi',\n",
       " 'if [ ! -z ${{secrets.CYPRESS_RECORD_KEY}} ]; then',\n",
       " '    npx cypress run -P ${{inputs.CYPRESS_PROJECT_PATH}} -C ${{inputs.CYPRESS_CONFIG_FILE}} -r ${{inputs.CYPRESS_REPORTER}} ${{inputs.ADDITIONAL_OPTIONS}} --record',\n",
       " 'else',\n",
       " '    npx cypress run -P ${{inputs.CYPRESS_PROJECT_PATH}} -C ${{inputs.CYPRESS_CONFIG_FILE}} -r ${{inputs.CYPRESS_REPORTER}} ${{env.ADDITIONAL_OPTIONS}}',\n",
       " 'fi']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps = get_steps(job)\n",
    "get_script(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7284d5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines []\n"
     ]
    }
   ],
   "source": [
    "lines = \"~/.npm\\n~/.cache/Cypress\\n\".splitlines()\n",
    "for line in lines:\n",
    "    print(line)\n",
    "print(\"Lines\", lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
